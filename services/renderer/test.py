import requests
import base64
from PIL import Image
import numpy as np
import cv2

# Load video for sample generation
video_path = "../../avatar_input/vinay_intro.mp4"
print(f"ğŸ¬ Loading video for sample generation: {video_path}")

cap = cv2.VideoCapture(video_path)
frames = []

if cap.isOpened():
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        # Convert BGR to RGB
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frames.append(frame)
    cap.release()
    print(f"âœ… Loaded {len(frames)} frames from video")
else:
    print(f"âŒ Could not open video file: {video_path}")
    exit(1)

# Convert to numpy array: (frames, height, width, channels)
video_array = np.array(frames)

# Test with sample audio (you can use any WAV file)
audio_file = "../../vinay_audio.wav"

# Send to renderer
response = requests.post("http://localhost:9000/render",
                        json={
                            "video": video_array.tolist(),
                            "audio_file": audio_file
                        })

# Debug: Check response
print(f"Response status: {response.status_code}")
print(f"Response content: {response.text}")

# Get animated frame
if response.status_code == 200:
    response_data = response.json()
    print(f"Response keys: {response_data.keys()}")
    if "frame" in response_data:
        animated_frame = response_data["frame"]
        print(f"âœ… Got animated frame! Status: {response_data.get('status')}")
        print(f"ğŸ“ Message: {response_data.get('message')}")
        
        # Decode and save the result
        frame_data = base64.b64decode(animated_frame)
        with open("generated_frame.png", "wb") as f:
            f.write(frame_data)
        print("ğŸ’¾ Saved generated frame as 'generated_frame.png'")
    else:
        print("âŒ No 'frame' key in response")
        print(f"Response: {response_data}")
else:
    print(f"âŒ Server error: {response.status_code}")
    print(f"Error details: {response.text}")